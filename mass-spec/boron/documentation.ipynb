{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Documentation\n",
        "author: Jie Xu & Dominik C. Hezel\n",
        "date: 'January 25, 2023'\n",
        "toc: true\n",
        "number-sections: true\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "---"
      ],
      "id": "ece71945"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Boron LA-ICP-MS Data Reduction Application\n",
        "\n",
        "## Introduction\n",
        "This program is capable of:\n",
        "\n",
        "- Read multiple .exp data files\n",
        "- Read additional .csv files\n",
        "- Outlier rejection\n",
        "- Background correction\n",
        "- Intra-sequence Instrumental drift correction\n",
        "- Ablation volume dependent B concentration offset correction\n",
        "- Combination of calculation results, laser parameters and trace elements results\n",
        "- Ready to use final data table\n",
        "\n",
        "\n",
        "## How to use the Progame\n",
        "\n",
        "1. Upload data files from Neptune: click the 'Browse files' botton, then, use 'command A' to choose all '.exp' data files required from Neptune.\n",
        "\n",
        "2. Set up parameters for isotopic data: \n",
        "   (1). drag slider to choose bacground and signal area. Orange color zone represents background, and blue color zone is signal area.\n",
        "   (2). set your outlier factor: with smaller number, more data will be cut as outlier, which can be observed from red spots. \n",
        "   (3). set the bulge factor for 11B factor: this is related with bulge correction from 10B, 0.6 here as a factor is defined by Dr. Axel Gerdes.\n",
        "   (4). choose your standard for intra-sequence instrumental drift correction: the name, the 'A/B/C/D' inside the name of standard, the regression level.\n",
        "\n",
        "3. Upload your log file from laser: click the 'Browse files' botton and choose your laser file. (have a check if it is matched with isotopic data.)\n",
        "\n",
        "4. Set up parameters for corrected boron concentration from signal intensity:\n",
        "   (1). the regression level for boron concentration correction.\n",
        "   (2). insert the depth of selected reference depth and other sample depth if you have. Otherwise, just keep it.\n",
        "   (3). insert the shape of your spots: circle or squre.\n",
        "   (4). tell us if you used split stream or not.\n",
        "\n",
        "*5. Upload your trace element file if you used split stream. (not necessary) \n",
        "\n",
        "6. download your final results as a csv file.\n",
        "\n",
        "\n",
        "## Input File Requirements\n",
        "\n",
        "1. Input datafiles from Neptune:\n",
        "   (1). '.dat', '.exp', '.log', '.TDT' four type of datafiles for each measurement would be produced. Only '.exp' can be read successfully and can be openned by excel. \n",
        "   (2). underds datafiles are named in a format of 'num-A/B/C/D/U'(e.g. ‘001-A’,  ‘002-B’), num represents sequence number, A/B/C/D are four label for standards, U is label for unknown samples. Attention: all datafiles in one sequence need to be all uploaded once!\n",
        "   (3). Inside each '.exp' datafile, data start from the 23th row, and columns('9.9', '10B',\t'10.2', '11B') are necessary for data processing according to our method. \n",
        "\n",
        "2. Input laser file:\n",
        "this is a csv file produced during abalation. Please have a check about all recorded information, which should be in the same order with Neptune datafile. Error may happen here.\n",
        "\n",
        "3. Input trace element datafile:\n",
        "trace element data required from Ladr here. Raw data should be processed by Ladr and be appended here.\n",
        "\n",
        "\n",
        "## Description of the Python Code\n",
        "\n",
        "Required packages\n"
      ],
      "id": "49fb2d74"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import statistics as stt\n",
        "from scipy import stats\n",
        "from scipy.optimize import curve_fit"
      ],
      "id": "f41012fc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uploading files, multiple files and only .exp files are allowed.\n"
      ],
      "id": "2e76948e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if st.button('clear uploaded data'):\n",
        "    st.session_state.uploaded_files = []\n",
        "\n",
        "if 'uploaded_files' in st.session_state and len(st.session_state.uploaded_files) != 0:\n",
        "    uploaded_files = st.session_state.uploaded_files\n",
        "\n",
        "else:\n",
        "    st.session_state.uploaded_files = st.file_uploader('upload files', type=['exp'], accept_multiple_files=True)"
      ],
      "id": "7358c258",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explaining the Functions\n",
        "-> Include here explanations of what the functions do to the data, e.g., why the regression, why higher orders: or – why the subtraction of the backgrounds, what two backgrounds exist: the ‘normal’ one, and one from an unknown source\n",
        "\n",
        "\n",
        "**def selSmpType(dataFiles)**\n",
        "\n",
        "Get the sequence number for each datafile from their file name. The sequence number can be used for Instrumental drift correction later."
      ],
      "id": "e0fa17b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def selSmpType(dataFiles):\n",
        "    l = []\n",
        "    for file in dataFiles:    \n",
        "        l.append(float(file.split('_')[0]))\n",
        "    return l"
      ],
      "id": "9cd09d07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def outlierCorrection(data, factorSD)**\n",
        "\n",
        "Outlier rejection of data, data is out of factorSD times of standard deviation will be taken as outliers.\n",
        "The first one is used for plot, the second one is used for calculation."
      ],
      "id": "058a331c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def outlierCorrection_plot(data, factorSD):\n",
        "    element_signal = np.array(data)\n",
        "    mean = np.mean(element_signal, axis=0)\n",
        "    sd = np.std(element_signal, axis=0)\n",
        "    fil = (data < mean + factorSD * sd) & (data > mean - factorSD * sd)\n",
        "    return fil\n",
        "\n",
        "\n",
        "def outlierCorrection(data, factorSD):\n",
        "    element_signal = np.array(data)\n",
        "    mean = np.mean(element_signal, axis=0)\n",
        "    sd = np.std(element_signal, axis=0)\n",
        "\n",
        "    return [x for x in data if (x > mean - factorSD * sd) and (x < mean + factorSD * sd)]"
      ],
      "id": "b3b242ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def parseBoronTable(file)**\n",
        "\n",
        "find the useful data body from uploaded '.exp' datafiles. "
      ],
      "id": "527552a0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def parseBoronTable(file):\n",
        "    #content = file.read()\n",
        "    content = file.getvalue().decode(\"utf-8\")\n",
        "    fname = file.__dict__[\"name\"]\n",
        "    _start = content.find(\"Cycle\\tTime\")\n",
        "    _end = content.find(\"***\\tCup\")\n",
        "    myTable = content[_start:_end-1]\n",
        "\n",
        "    cleanFname = f\"temp/{fname}_cleanTable\"\n",
        "    with open(cleanFname, \"w\") as _:\n",
        "        _.write(myTable)\n",
        "\n",
        "    df = pd.read_csv(cleanFname,\n",
        "                     sep='\\t',\n",
        "                     # dtype=\"float\"   #not working -->time\n",
        "                     )\n",
        "\n",
        "    return df, fname"
      ],
      "id": "f91dd074",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def sig_selection()**\n",
        "\n",
        "Plot the signal selection zone."
      ],
      "id": "22e95204"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# st.session_state.sample_plot = st.selectbox(\n",
        "#     'Which is your sample to plot?',\n",
        "#     (st.session_state.uploaded_files))\n",
        "    \n",
        "# def sig_selection():\n",
        "#     average_B = []\n",
        "#     df_data, filename = parseBoronTable(st.session_state.sample_plot)\n",
        "#     df_data = df_data[['Cycle', '9.9', '10B', '10.2', '11B']].astype(float)\n",
        "\n",
        "#     fig, ax = plt.subplots()\n",
        "#     ax.plot(df_data['11B'], label='11B', c='green')\n",
        "#     ax.plot(df_data['10B'], label='10B', c='firebrick')\n",
        "#     ax.set_ylabel('signal intensity')\n",
        "#     ax.set_xlabel('cycle')\n",
        "#     x = df_data['11B'].index.to_numpy()\n",
        "#     ax.fill_between(x, max(df_data['11B']), where=(\n",
        "#         x < st.session_state.sig_end) & (x > st.session_state.sig_str), alpha=0.5)\n",
        "#     ax.fill_between(x, max(df_data['11B']), where=(\n",
        "#         x < st.session_state.bac_end) & (x > st.session_state.bac_str), alpha=0.5)\n",
        "\n",
        "#     ax.legend()\n",
        "#     return fig"
      ],
      "id": "61bbf16b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def bacground_sub(factorSD, factor_B11)**\n",
        "\n",
        "Background subtraction. ‘9.9’, '10B', ’10.2’ and ‘11B’ are useful data here.\n",
        "(1). noise substraction from each cup.\n",
        "(2). bulge is defined by ‘9.9’ and ’10.2’. The average value of ‘9.9’ and ’10.2’ is applied for 10B correction, multiply 0.6 of the average value is applied for 11B correction.\n",
        "(3). the outlier data is plotted here.\n",
        "(4). the average of 11B/10B, standard deviation and name of datafile are returned.\n"
      ],
      "id": "7b675379"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def bacground_sub(factorSD, factor_B11):\n",
        "    average_B = []\n",
        "    for i in st.session_state.uploaded_files:\n",
        "        df_data, filename = parseBoronTable(i)\n",
        "        df_data = df_data[['Cycle', '9.9', '10B', '10.2', '11B']].astype(float)\n",
        "\n",
        "        df_bacground_mean = df_data[st.session_state.bac_str:st.session_state.bac_end].mean()\n",
        "        df_signal = df_data[st.session_state.sig_str:st.session_state.sig_end]\n",
        "\n",
        "        df_bacground_sub = df_signal - df_bacground_mean\n",
        "        df_bacground_sub['10B_bulc_sub'] = df_bacground_sub['10B'] - \\\n",
        "            (df_bacground_sub['9.9']+df_bacground_sub['10.2'])/2\n",
        "        df_bacground_sub['11B_bulc_sub'] = df_bacground_sub['11B'] - \\\n",
        "            factor_B11*(df_bacground_sub['9.9']+df_bacground_sub['10.2'])/2\n",
        "        df_bacground_sub['11B/10B'] = df_bacground_sub['11B_bulc_sub'] / \\\n",
        "            df_bacground_sub['10B_bulc_sub']\n",
        "        fil = outlierCorrection_plot(df_bacground_sub['11B/10B'], factorSD)\n",
        "        res_iso = df_bacground_sub['11B/10B'][fil]\n",
        "        res_iso_outlier = df_bacground_sub['11B/10B'][~fil]\n",
        "        res_11B = outlierCorrection(df_bacground_sub['11B'], factorSD)\n",
        "        if i == st.session_state.sample_plot:\n",
        "            fig1, ax = plt.subplots()\n",
        "            ax.plot(df_bacground_sub['11B/10B'], 'ko')\n",
        "            ax.plot(res_iso_outlier, 'ro', label='outliers')\n",
        "            ax.set_ylabel('$^{11}B$/$^{1O}B$')\n",
        "            ax.legend()\n",
        "            st.pyplot(fig1)\n",
        "        average_B.append({'filename': filename, '11B': np.mean(\n",
        "            res_11B), '11B/10B_row': np.mean(res_iso), 'se': np.std(res_iso)/np.sqrt(len(res_iso))})\n",
        "\n",
        "    df = pd.DataFrame(average_B)\n",
        "    st.session_state.average_B = df\n",
        "\n",
        "    return df"
      ],
      "id": "34026d21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def polynomFit(inp, \\*args)**\n",
        "\n",
        "used for regression function."
      ],
      "id": "9ff54648"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def polynomFit(inp, *args):\n",
        "    x=inp\n",
        "    res=0\n",
        "    for order in range(len(args)):\n",
        "        res+=args[order] * x**order\n",
        "    return res"
      ],
      "id": "a2192175",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def regression(x, y, ref_stand, order, listname)**\n",
        "\n",
        "Get the correction function of the Intra-sequence Instrumental drift."
      ],
      "id": "d2ec2813"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def regression(x, y, ref_stand, order, listname):\n",
        "    x_use = np.array(x)\n",
        "    popt, pcov = curve_fit(polynomFit, xdata=x_use, ydata=y , p0=[0]*(order+1))\n",
        "    fitData=polynomFit(x_use,*popt)\n",
        "    \n",
        "    res = []\n",
        "    for unknown in listname:\n",
        "        y_unknown = ref_stand / polynomFit(unknown,*popt)\n",
        "        res.append({'factor': y_unknown})\n",
        "    return(pd.DataFrame(res))"
      ],
      "id": "b2f085e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def regression_plot(x, y, ref_stand, order, listname)**\n",
        "\n",
        "Return the plot the regress line."
      ],
      "id": "ec239484"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def regression_plot(x, y, ref_stand, order, listname):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(x, y, label='measuered', marker='o', linestyle='none' )\n",
        "    x_use = np.array(x)\n",
        "    popt, pcov = curve_fit(polynomFit, xdata=x_use, ydata=y , p0=[0]*(order+1))\n",
        "    fitData=polynomFit(x_use,*popt)\n",
        "    ax.plot(x_use, fitData, label='polyn. fit, order '+str(order), linestyle='--' )\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1.05, 1))\n",
        "    \n",
        "    return fig"
      ],
      "id": "42888788",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def prepare_trace(datafile)**\n",
        "\n",
        "Prepare trace element datafile from Ladr: change the column titles and change data formate from str to float."
      ],
      "id": "2f4600f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def prepare_trace(datafile):\n",
        "    if 'LR' in datafile.columns[14]:\n",
        "        del datafile['44Ca(LR)']\n",
        "        del datafile['26Mg(LR)']\n",
        "    else:\n",
        "        del datafile['44Ca']\n",
        "        del datafile['26Mg']\n",
        "\n",
        "    datafile.columns = datafile.columns.str.replace('\\d+', '')\n",
        "    datafile.columns = datafile.columns.str.replace('\\('+'LR'+'\\)', '')\n",
        "    res = []\n",
        "    for i in range(13, len(datafile.columns)):\n",
        "        for j in datafile.iloc[:, i]:\n",
        "            if '<' in j:\n",
        "                res.append(j)\n",
        "    RES = datafile.replace(to_replace=res, value='nan', regex=True)\n",
        "    RES2 = RES.replace(\n",
        "        {'ERROR: Error (#1002): Internal standard composition can not be 0': np.nan})\n",
        "    RES3 = RES2.replace(\n",
        "        {'ERROR: Error (#1003): Calibration RM composition does not contain analyte element': np.nan})\n",
        "    RES4 = RES3.iloc[:, 13:].astype(float)\n",
        "    columns = RES4.iloc[:, 13:].columns\n",
        "    RES4[columns] = RES4.iloc[:, 13:]\n",
        "    RES4[' Sequence Number'] = RES3['LB#']\n",
        "    return(RES4)"
      ],
      "id": "b742f477",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def processData()**\n",
        "\n",
        "Use functions for Intra-sequence Instrumental drift."
      ],
      "id": "e3cbb135"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def processData():\n",
        "    st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "    st.subheader('1.1 select your background and signal area')\n",
        "    st.session_state.bac_str, st.session_state.bac_end = st.slider('Select bacground', 0, 200, (5, 70))\n",
        "    st.session_state.sig_str, st.session_state.sig_end = st.slider('Select signal', 0, 200, (95, 175))\n",
        "    st.pyplot(sig_selection())\n",
        "\n",
        "    st.subheader('1.2 Please set your outlier and bulge factor')\n",
        "    outlier_factor = st.number_input('insert your outlier factor (means data is outlier_factor times of sd will be cut)',\n",
        "                                     value=1.5)\n",
        "    bulc_factor = st.number_input(\n",
        "        'insert your bulge factor for 11B correction', value=0.6)\n",
        "\n",
        "\n",
        "\n",
        "    if \"average_B\" in st.session_state:\n",
        "        df_data = st.session_state.average_B\n",
        "    else:\n",
        "        df_data = bacground_sub(outlier_factor, bulc_factor)\n",
        "\n",
        "    st.subheader(\n",
        "        '1.3 Please choose your standard for boron isotopes correction')\n",
        "\n",
        "    standard = st.selectbox(\n",
        "        'NIST 612 or B5 for correction?',\n",
        "        ('NIST SRM 612', 'B5'))\n",
        "    if standard == 'B5':\n",
        "        number_iso = int(4.0332057)\n",
        "        number_trace = int(8.42)\n",
        "        SRM951_value = int(4.0492)\n",
        "\n",
        "    if standard == 'NIST SRM 612':\n",
        "        number_iso = int(4.05015)\n",
        "        number_trace = int(35)\n",
        "        SRM951_value = int(4.0545)\n",
        "\n",
        "    st.session_state.standard_values = {\n",
        "        \"number_iso\" : number_iso,\n",
        "        \"number_trace\" : number_trace,\n",
        "        \"SRM951_value\" : SRM951_value\n",
        "\n",
        "    }\n",
        "\n",
        "    st.session_state.sample_correction = st.selectbox(\n",
        "        'Which type is your choosed standard?',\n",
        "        ('A', 'B', 'C', 'D'))\n",
        "\n",
        "    st.session_state.default_reg_level = 4\n",
        "    st.session_state.regress_level = st.number_input('insert your regression level (4 is recommended)', step=1, value=st.session_state.default_reg_level, format='%X'\n",
        "                                                     )\n",
        "    fil = df_data['filename'].str.contains(st.session_state.sample_correction)\n",
        "    df_data_B = df_data[fil]\n",
        "    df_data[' Sequence Number'] = selSmpType(df_data['filename'])\n",
        "\n",
        "    y_isotope = df_data_B['11B/10B_row']\n",
        "    y_11B = df_data_B['11B']\n",
        "    x = df_data_B.index.to_numpy()\n",
        "\n",
        "    factor_iso = regression(x, y_isotope,\n",
        "                            number_iso,\n",
        "                            st.session_state.regress_level if \"regress_level\" in st.session_state else st.session_state.default_reg_level,\n",
        "                            df_data.index.to_numpy()\n",
        "                            )\n",
        "\n",
        "    df_data['factor_iso'] = factor_iso\n",
        "\n",
        "    df_data['11B/10B_corrected'] = df_data['factor_iso']*df_data['11B/10B_row']\n",
        "    df_data['δ11B'] = ((df_data['11B/10B_corrected']/SRM951_value)-1)*1000\n",
        "    df_data['δ11B_se'] = (df_data['se']*df_data['factor_iso']/SRM951_value)*1000\n",
        "\n",
        "    st.session_state.df_data = df_data\n",
        "    st.session_state.df_data_B = df_data_B"
      ],
      "id": "1c679a4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def processLaser()**\n",
        "\n",
        "Use functions and volume factors for corrected boron concerntrations."
      ],
      "id": "feac58cc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def processLaser():\n",
        "    if \"df_data\" in st.session_state:\n",
        "        st.header('2. Please upload your log file from Laser')\n",
        "        st.session_state.uploaded_laser_file = st.file_uploader(\"Choose a laser file\", type='csv')\n",
        "        if st.session_state.uploaded_laser_file is not None:\n",
        "            st.session_state.df_Laser = pd.read_csv(st.session_state.uploaded_laser_file)\n",
        "\n",
        "            st.session_state.df_Laser_part1 = st.session_state.df_Laser[st.session_state.df_Laser[' Laser State']\n",
        "                                    == 'On'].iloc[:, [13, 20, 21]]\n",
        "            st.session_state.df_Laser_part2 = st.session_state.df_Laser[st.session_state.df_Laser[' Sequence Number'].notnull()].iloc[:, [\n",
        "                    1, 4]]\n",
        "\n",
        "            st.session_state.df_Laser_res = pd.concat([st.session_state.df_Laser_part2.reset_index(\n",
        "                    drop=True), st.session_state.df_Laser_part1.reset_index(drop=True)], axis=1)\n",
        "                    \n",
        "            st.session_state.df_map1 = st.session_state.df_Laser_res.merge(st.session_state.df_data, on=' Sequence Number')\n",
        "\n",
        "            st.subheader('2.1 B concerntration correction')\n",
        "            st.session_state.regress_level_B = st.number_input('insert your regression level for [B] (4 is recommended)', \n",
        "            step=1, \n",
        "            value=st.session_state.default_reg_level, \n",
        "            format='%X'\n",
        "                                                            )     \n",
        "\n",
        "            y_isotope = st.session_state.df_data_B['11B/10B_row']\n",
        "            y_11B = st.session_state.df_data_B['11B']\n",
        "            x = st.session_state.df_data_B.index.to_numpy()   \n",
        "            factor_B = regression(x, y_11B, st.session_state.standard_values[\"number_trace\"],\n",
        "                            st.session_state.regress_level_B if \"regress_level_B\" in st.session_state else st.session_state.default_reg_level_B, \n",
        "                            st.session_state.df_data.index.to_numpy()\n",
        "                            )\n",
        "            st.session_state.df_map1['factor_B'] = factor_B\n",
        "            \n",
        "\n",
        "            depth_ref = st.number_input('insert the abalation depth of selected reference / µm', value = 30.0)\n",
        "            depth_sample = st.number_input('insert the abalation depth of other samples / µm', value = 30.0)\n",
        "                    \n",
        "            depth_ratios = []\n",
        "            for i in st.session_state.df_map1['filename'].str.contains('A'):\n",
        "                if i == True:\n",
        "                    depth_ratio = 1 \n",
        "                else:\n",
        "                    depth_ratio = depth_sample / depth_ref\n",
        "                depth_ratios.append(depth_ratio)\n",
        "\n",
        "            st.session_state.df_map1['depth_correction'] = depth_ratios\n",
        "\n",
        "            spot_shape = st.selectbox(\n",
        "                        'What is the type of your spots?',\n",
        "                        ('circle', 'squre'))\n",
        "            if spot_shape == 'circle':\n",
        "                st.session_state.df_map1[' Spot Size (um)'] = st.session_state.df_Laser_res[' Spot Size (um)']\n",
        "                ref = ((st.session_state.df_map1[st.session_state.df_map1['filename'].str.contains(st.session_state.sample_correction)][' Spot Size (um)']/2)**2).mean()\n",
        "                st.session_state.df_map1['[B]_corrected'] = st.session_state.df_map1['11B']*st.session_state.df_map1['factor_B'] * (ref / ((st.session_state.df_map1[' Spot Size (um)']/2)**2) / depth_ratios)\n",
        "\n",
        "            if spot_shape == 'squre':\n",
        "\n",
        "                dia = st.session_state.df_map1[' Spot Size (um)']\n",
        "                spotsize = dia.str.split(' ').str[0].apply(lambda x: float(x))\n",
        "                st.session_state.df_map1[' Spot Size (um)'] = spotsize\n",
        "                ref = ((st.session_state.df_map1[st.session_state.df_map1['filename'].str.contains(st.session_state.sample_correction)][' Spot Size (um)'])**2).mean()\n",
        "                st.session_state.df_map1['[B]_corrected'] = st.session_state.df_map1['11B']*st.session_state.df_map1['factor_B'] * (ref / ((st.session_state.df_map1[' Spot Size (um)'])**2) / depth_ratios)   \n",
        "    \n",
        "            st.session_state.df_map1 = st.session_state.df_map1\n"
      ],
      "id": "ba997bd2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def maping()**\n",
        "\n",
        "upload trace element datafile and merge laser parameter, isotopic results and trace element compositions into one file based on sequence number."
      ],
      "id": "d563b6f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def maping():\n",
        "    if \"df_map1\" in st.session_state:\n",
        "        st.subheader('2.2 export results or append your trace elements')\n",
        "\n",
        "        trace_file = st.selectbox(\n",
        "            'split stream or not?',\n",
        "            ('Split stream', 'No'))\n",
        "\n",
        "        if trace_file == 'No':\n",
        "            st.session_state.df_all = st.session_state.df_map1\n",
        "\n",
        "\n",
        "        elif trace_file == 'Split stream':\n",
        "            st.header('3. Please upload your trace element data processed from Ladr')\n",
        "\n",
        "            st.session_state.trace = st.file_uploader(\"Choose a file\", type='csv', accept_multiple_files=True)\n",
        "            if \"trace\" in  st.session_state and len(st.session_state.trace) > 0:\n",
        "\n",
        "                trace_file = pd.read_csv(st.session_state.trace[0])\n",
        "\n",
        "                #trace_file = pd.read_csv('2022-11-28-Si corrected-B5.csv')\n",
        "\n",
        "                df_trace = prepare_trace(trace_file)\n",
        "\n",
        "                st.session_state.df_all = st.session_state.df_map1.merge(df_trace, on=' Sequence Number')\n",
        "                # fig4, ax = plt.subplots()\n",
        "                # ax.plot([0,1],[0,1], transform=ax.transAxes, c = 'red')\n",
        "                # ax.scatter(st.session_state.df_all['[B]_corrected'], st.session_state.df_all['B'], s =70, c = 'darkorange', edgecolors = 'black')\n",
        "                # ax.set_ylabel('[B]_measured by Element')\n",
        "                # ax.set_xlabel('[B]_corrected by Neptune')\n",
        "                # st.pyplot(fig4)\n",
        "\n",
        "\n",
        "        if \"df_all\" in st.session_state:\n",
        "            st.session_state.df_all.to_csv('final.csv')\n",
        "            st.write(st.session_state.df_all)\n",
        "            result_csv = st.session_state.df_all.to_csv().encode('utf-8')\n",
        "            st.download_button(\n",
        "                label='download results as .csv',\n",
        "                data=result_csv,\n",
        "                file_name='boron results.csv',\n",
        "                mime='txt/csv',\n",
        "            )\n"
      ],
      "id": "cb440614",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###\tExplaining the Main Body of the Code\n",
        "run thw function: "
      ],
      "id": "6faf5449"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# if len(st.session_state.uploaded_files) != 0:\n",
        "#     processData()\n",
        "\n",
        "# processLaser()\n",
        "# maping()\n"
      ],
      "id": "d53fe0c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explain the Output\n",
        "\n",
        "What exactly is the output, likely best with screen shots.\n",
        " \n",
        "-->’Sequence Number’ column: the number of datafile in all sequence.\n",
        "-->The ‘Comment’ column: sample name, labelled by yourself during measuring.\n",
        "--> ‘Spot size (um)’, ‘Laser HV (kV)’, ‘Laser Energy (mJ)’: useful information selected from laser parameters.\n",
        "-->The ‘filename’ column: name of datafile.\n",
        "-->from ‘11B’ to ‘factor_iso’: all results from Neptune. ‘[B]_corrected’ is calculated B concentrations from 11B. ‘δ11B’ and ‘δ11B_se’column are calculated isotope results and erros.\n",
        "-->from ‘Li’, ‘B’ to ‘U’ are all trace element results from Element XR.\n",
        "\n",
        "(the following is copied from what was a ‘text’ file.)\n",
        "1. csv files are changed from original .exp file\n",
        "2. data automatically from machine can be found in 'data/original data type'.\n",
        "\n",
        "\n",
        "## Testing\n",
        "\n",
        "For a demonstration of a line plot on a polar axis, see @fig-polar.\n"
      ],
      "id": "64210db4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-polar\n",
        "#| fig-cap: A line plot on a polar axis\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "r = np.arange(0, 2, 0.01)\n",
        "theta = 2 * np.pi * r\n",
        "fig, ax = plt.subplots(\n",
        "  subplot_kw = {'projection': 'polar'} \n",
        ")\n",
        "ax.plot(theta, r)\n",
        "ax.set_rticks([0.5, 1, 1.5, 2])\n",
        "ax.grid(True)\n",
        "plt.show()"
      ],
      "id": "fig-polar",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}